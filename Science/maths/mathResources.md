### Links
- https://intuitive-math.club/
- https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/videos (3Blue1Brown)

### Tom M
http://www.cs.cmu.edu/~ninamf/courses/601sp15/index.html

###[Book]
"Introduction to Information Retrieval", C. Manning, P. Raghavan, H. Schutze, Cambridge University Press.
http://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf

### Data Mining Reference Books
- "Text Mining - Classification, Clustering, and Applications", A. Srivastava and M. Sahami, CRC Press.
- "Mining Text Data", C.C. Aggarwal and C.X. Zhai, Springer Science.
- "Introduction to Information Retrieval", C. Manning, P. Raghavan, H. Schutze, Cambridge University Press.
- "Machine Learning: A Probabilistic Perspective", K. Murphy, The MIT Press.
- "Pattern Recognition and Machine Learning", C.M. Bishop, Springer.
1. "Probabilistic Topic Models", by Blei, Communications of the ACM, Vol. 55, No. 4, pp.77-84, 2012. 
2. "Topic Models" by Blei and Lafferty, book chapter In Text Mining: Classification, Clustering, and Applications, Chapter 4, Srivastava and Sahami, CRC Press. 
3. "Probabilistic Topic Models" by Steyvers and Griffiths, book chapter in Latent Semantic Analysis: A Road to Meaning, Landauer, McNamara, Dennis, and Kintsch, Laurence Erlbaum.

### Lecture Notes on text mining
http://www1.se.cuhk.edu.hk/~seem5680/


### Abstract Algebra Resources
- [pinter: abstract algebra - self study friendly]
http://www2.math.umd.edu/~jcohen/402/Pinter%20Algebra.pdf 
- [Video of the lectures found under the link for schedule]
https://www.math.upenn.edu/~ted/371F14/math371.html
- [Free book: Abstract algebra theory and patterns]
http://abstract.ups.edu/download/aata-20160809-sage-7.3.pdf


### [Course] stanford cs205
- http://graphics.stanford.edu/courses/cs205a-16-spring/index.html
- http://graphics.stanford.edu/courses/cs205a-16-spring/schedule.html
- [Book] Numerical Algorithms: Methods for Computer Vision, Machine Learning, and Graphics
- https://www.amazon.com/Numerical-Methods-Computer-Learning-Graphics/dp/1482251884


### Statistical Inference
- https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/video-lectures/lecture-23-classical-statistical-inference-i/
- http://isites.harvard.edu/icb/icb.do?keyword=k101665&pageid=icb.page656049

### statistical aspects of datamining
- https://www.youtube.com/watch?v=zRsMEl6PHhM

### Exercises from Gilbert Strang 4'th edition
- https://web.williams.edu/Mathematics/sjmiller/public_html/BrownClasses/54/HWStrang4thEd.pdf


### Paper on netflix prize
- http://buzzard.ups.edu/courses/2014spring/420projects/math420-UPS-spring-2014-gower-netflix-SVD.pdf
- http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/


### [Book] Free book to introduction of svd, pca and others
- http://www.cs.cmu.edu/~venkatg/teaching/CStheory-infoage/
- http://www.cs.wustl.edu/~zhang/teaching/cs517/Spring12/CourseProjects/SVD.pdf

### [Book] Introduction to probability
- https://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science/dp/1466575573

### [Book] Introduction to probability with R
- https://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science/dp/1420065211

### Lecture Notes on randomized linear algebra
- https://arxiv.org/abs/1608.04481v1

### [Book] Applied mathematics for database professional
- http://www.apress.com/us/book/9781590597453

### Stanford CS229 Machine learning class with material updated each year
- http://cs229.stanford.edu/
- the pdf of lecture notes
- review notes
- project details for each year

### [Book]Calculus In Context
- http://www.math.smith.edu/Local/cicintro/book.pdf
- http://www.math.smith.edu/Local/cicintro/

### Convex Optimization
- http://stanford.edu/class/ee364a/videos/video01.html

### Introduction to linear dynamical systems
- https://www.youtube.com/playlist?list=PL06960BA52D0DB32B
- http://ee263.stanford.edu/lectures.html

### MIT : 18.06 Linear Algebra archives
- http://web.mit.edu/18.06/www/
-solutions https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/assignments/

#### Why nontrivial rotation matrices cannot have real eigenvectors ? 
#### What is the intuition behind that?

### Understanding the rotation matrix
- http://scipp.ucsc.edu/~haber/ph216/rotation_12.pdf

### What is an intuitive explanation of the spectral theorem
- https://www.quora.com/What-is-an-intuitive-explanation-of-the-spectral-theorem

### The Intution Behind Real Symmetric Matrices and Their Real Eigenvectors
- http://math.stackexchange.com/questions/1413763/the-intution-behind-real-symmetric-matrices-and-their-real-eigenvectors

### Intuition of symmetric matrix

### Intuition behind transpose of matrix
- http://math.stackexchange.com/questions/37398/what-is-the-geometric-interpretation-of-the-transpose

### QR transformation intution
- http://www.cs.cornell.edu/courses/cs3220/2009sp/notes/qr.pdf

### qr orthogonalization intuition
- http://math.stackexchange.com/questions/598258/determinant-of-transpose/636198#636198

### Geometric Intuition for transpose
- http://math.stackexchange.com/questions/598258/determinant-of-transpose/636198#636198

### Mathematical Intuition
- https://sites.google.com/site/butwhymath/algebra/the-quadratic-formula

### Intuition of dual space:
- This post provides a great intuition of dual space
- http://math.stackexchange.com/questions/1502970/what-is-a-dual-space
In the context of vector spaces, the dual space is a space of linear "measurements". When a dual vector ff acts on a vector vv, the scalar output f(v)f(v) provides information about vv; in particular, it gives you something about a coordinate of vv in some direction. A vector vv can be reconstructed from knowing all the values f(v)f(v) for ff in the dual space.
As a rough example from engineering, consider vector space VV the space of continuous, periodic functions on [0,2π][0,2π]. Then there are certain dual vectors fkfk which returns how much of the function v(x)∈Vv(x)∈V contains a frequency kk. So if v(x)v(x) was a sound wave, then fk(v)fk(v) tells you whether the musical note of frequency kk is in the sound. Then the entire sound wave v(x)v(x) can be reconstructed from knowing fk(v)fk(v) for all kk, since that would tell you all the notes in the sound.
And of course, fk(v)fk(v) is going to be the kkth Fourier coefficient of vv.

### Now try to relate that intuition to the concept present in this link
http://math.stackexchange.com/questions/3749/why-do-we-care-about-dual-spaces?rq=1

### Intuition about Quotient Space
V/U is all the space that are parallel to U. When U is squished to a point, V/U is the resultant
Eg: Let V be R^3 and U be R^2
Then V/U is the space of all lines that are parallel to U. But U is squished to zero in this space. 
So all the lines that parallel to U are just points in V/U. 
Dimension of V/U is 3 -2 = 1. These are just points.
We can imagine these points (all the parrallel lines) to lie as points in a line in another two dimensional space

### Playlist on Vector Space. Saw the dual space explanation and looks easy to grasp on
https://www.youtube.com/watch?v=KMlzcvmhaLA&list=PLAvgI3H-gclbucHp-i_p1OxzeFxadw8b3
Dual vector spaces
https://www.youtube.com/watch?v=SjCs_HyYtSo


--------------------------------------------------------------------------------
1. Try questions in linear algebra to poke understanding with more emphasis on geometric intutuion than methods to find the answers to solutions

### References
- Practical Linear Algebra : Get the geometric intuitions around LA basic
  concepts
- Linear Algebra a modern introduction : LA with examples of applications
- Coding the matrix : LA from computer science perspective

### Use LA references to study data mining book

- Understanding complex datasets : With matrix decompositions
- Matrix methods in data mining and pattern recognition

### Tools
- openGL to visualize the LA tranformations wrt graphics

### ML
- Machine learning a probabilistic perspective
